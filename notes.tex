\documentclass[12pt]{article}
\usepackage[margin=1.25in]{geometry}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{hyperref}
\usepackage{dsfont}
\newtheorem{mydef}{Definition}

%%%%%%%%%%%%%
% These are a few commands which I have found useful over the years..
%%%%%%%%%%%%%
\newcommand{\norm}[1]{\left|\left|#1\right|\right|}
\newcommand{\abs}[1]{\left|#1\right|}
\newcommand{\bx}{\mathbf{x}}
\newcommand{\bu}{\mathbf{u}}
\newcommand{\floor}[1]{\lfloor #1 \rfloor}
\newcommand{\ceil}[1]{\lceil#1 \rceil}
\newcommand{\bv}{\mathbf{v}}
\newcommand{\bbZ}{\mathds{Z}}
\newcommand{\bbR}{\mathds{R}}
\newcommand{\bbC}{\mathds{C}}
\newcommand{\bbN}{\mathds{N}}
\newcommand{\bbQ}{\mathds{Q}}
\newcommand{\bbzw}{\mathds{Z}[\omega]}
\newcommand{\bbzi}{\mathds{Z}[i]}
\newcommand{\nZ}[1][n]{\ensuremath{\mathds{Z}/#1\mathds{Z}}}
\newcommand{\<}{\langle}
\renewcommand{\>}{\rangle}

\title{AM 120 Notes}
\date{\today}
\author{Bannus Van der Kloot}

\begin{document}
\maketitle

\tableofcontents

\section{September 6 Lecture}

There are two main problems that we will learn how to handle in this class.

\begin{enumerate}
	\item Find $x \in R^n$ such that $Ax=b$. $A$ is $m$ by $n$ matrix, $b \in R^n$ vector
	\item Find $x$ and $\lambda$ such that $Ax = \lambda x$
\end{enumerate}

\paragraph{Example}

\begin{tabular}{rr}
	$x + 2y = 3$ \\
	$4x + 5y = 6$
\end{tabular}

$$ A =
\begin{bmatrix}
	1 & 2 \\
	4 & 5 
\end{bmatrix}
\begin{bmatrix}
	x \\ y
\end{bmatrix}
=
\begin{bmatrix}
	3 \\ 6
\end{bmatrix}
$$

There are 3 ways to solve:
\begin{enumerate}
	\item $\begin{bmatrix}
		1 & 2 & 3 \\
		4 & 5 & 6
	\end{bmatrix} \Rightarrow
	\begin{bmatrix}
		1 & 2 & 3 \\
		0 & -3 & -6
	\end{bmatrix}\Rightarrow
	y=2,x=-1$ 
	\item $A^{-1}=\frac{1}{\text{det}(A)}
	\begin{bmatrix}
		5 & -2 \\
		-4 & -1 
	\end{bmatrix}$
	$det A = -3$ \\
	$x=A^{-1}b \Rightarrow \frac{1}{-3}
	\begin{bmatrix}
		+3 \\ -6
	\end{bmatrix}$
	\item Kramer's rule
\end{enumerate}

\paragraph{Summary}
Topics covered in next 3 classes:
\begin{enumerate}
	\item Geometric interpretation of solving linear systems
	\item Matrix notation (LU factorization)
	\item Singular cases (no solution, multiple soln's)
	\item Efficient way to solve $Ax=b$ using computers
\end{enumerate}

\subsection{Geometric interpretation}

\paragraph{Example} Graphical method:

Row interpretation (plot lines on coordinate system):

\begin{tabular}{c}
	$2x - y = 1$ \\
	$x + y = 5$
\end{tabular}
Solution: $x=2,y=3$

Column interpretation:

$$ \begin{bmatrix}
	2 \\ 1
\end{bmatrix} x + 
\begin{bmatrix}
	-1 \\ 1
\end{bmatrix} y =
\begin{bmatrix}
	1 \\ 5
\end{bmatrix}$$

\paragraph{Example} 3 by 3 system:

Each row represents a plane:

\begin{tabular}{c}
	2u + v + w = 5 \\
	4u - 6v + 0 = -2 \\
	-2u + 7v + 2w = 9
\end{tabular}

Remember: inner product of vector with another vector equals 0 $\Rightarrow$ orthogonal.

Column interpretation:

\[
	\begin{bmatrix}
		2 \\ 4 \\ 2
	\end{bmatrix} u + 
	\begin{bmatrix}
		1 \\ -6 \\ 7
	\end{bmatrix} v + 
	\begin{bmatrix}
		1 \\ 0 \\ 2
	\end{bmatrix} w =
	\begin{bmatrix}
		5 \\ -2 \\ 9
	\end{bmatrix}
\]

\paragraph{Example} Overdetermined system:
\[
	\begin{bmatrix}
		1 & 1 \\
		2 & 3 \\
		3 & 4 \\
	\end{bmatrix}
	\begin{bmatrix}
		c \\ d
	\end{bmatrix} = 
	\begin{bmatrix}
		2 \\ 5 \\ 7
	\end{bmatrix}
\]

Solution: $c = 1, d = 1$

In 4 dimensions, the rows represent 3-spaces, which are `flat' relative to 4 dimensional space. If we intersect $(x,y,z,t=0)$ with $(x,y,z=0,t)$, two three spaces, we get $(x,y)$ plane.

\[
	a_1 u + a_2 v + a_3 w + a_4 z = b
\]

\[
	A = (a_1 | a_2 | a_3 | a_4)
\]

\subsection{Algorithmic approach}
Generalizing to $n$ by $n$. How to solve $Ax = b$ in a way that scales well? Gaussian elimination (row reduction).


\begin{tabular}{c}
	$2u + v + w = 5$ \\
	$4u - 6v + 0 = -2$ \\
	$-2u + 7v + 2w = 9$ \\\hline
\end{tabular}

$\Rightarrow$
\begin{tabular}{c}
	$2u + v + w = 5$ \\
	   $-8v - 2w = -12$ \\
         $8v + 3w = 14$ \\\hline
\end{tabular}

$\Rightarrow$
\begin{tabular}{c}
	$2u + v + w = 5$ \\
	   $-8v - 2w = -12$ \\
         $w = 2$ \\\hline
\end{tabular}

$\Rightarrow v = 1, u = 1$

We need a process that takes:

\[
	A = \begin{bmatrix}
		2 & 1 & 1 \\
		4 & -6 & 0 \\
		-2 & 7 & 2 \\
	\end{bmatrix}
\]
\[
	x = \begin{bmatrix}
		u \\ v \\ w
	\end{bmatrix}
\]
\[
	b = \begin{bmatrix}
		5 \\ -2 \\ 9
	\end{bmatrix}
\]

...this $Ax=b$ problem and transforms it to a $Ux = \hat{b}$ problem. We can get an upper triangular matrix, and obtain solution by back substitution.

\paragraph{Problems} One issue that could arise is if the bottom row is all 0s: infinitely many solutions.

\section{September 11 Lecture}

Last class:
\begin{itemize}
	\item Introduced first central problem of linear algebra: solving linear equations
	\item Studied column and row interpretation of linear systems
	\item Introduced Gaussian elimination
\end{itemize}

\paragraph{Example} (from previous class) Row/Column interpretation.

\begin{tabular}{c}
	2u + v + w = 5 \\
	4u - 6v + 0 = -2 \\
	-2u + 7v + 2w = 9
\end{tabular}

Row: Three planes intersecting. Column: linear combination of three vectors

\[
	A = \begin{bmatrix}
		2 & 1 & 1 \\
		4 & -6 & 0 \\
		-2 & 7 & 2 \\
	\end{bmatrix}
\]

We were trying to figure out how to transform matrix $A$ into an upper triangular matrix.

\[
	\begin{bmatrix}
		1 & 0 & 0 \\
		-2 & 1 & 0 \\
		0 & 0 & 1 \\
	\end{bmatrix}
	\begin{bmatrix}
		5 \\ -2 \\ 9
	\end{bmatrix}
	=
	\begin{bmatrix}
		5 \\ -12 \\ 9
	\end{bmatrix}
\]

\[
	\begin{bmatrix}
		1 & 0 & 0 \\
		-2 & 1 & 0 \\
		0 & 0 & 1 \\
	\end{bmatrix}
	\begin{bmatrix}
		2 & 1 & 1 \\
		4 & -6 & 0 \\
		-2 & 7 & 2 \\
	\end{bmatrix} = 
	\begin{bmatrix}
		2 & 1 & 1 \\
		0 & -8 & -2 \\
		-2 & 7 & 2 \\
	\end{bmatrix}
\]

\paragraph{Matrix operations} Addition is associative: $A+B+C = (A+B) + C = A+ (B+C)$

Multiplication: dimension $m \times n$ multiplied by $n \times p$ results in $m \times p$ matrix. $AB \neq BA$.

\[
	\begin{bmatrix}
		0 & 1 \\ 1 & 0\\
	\end{bmatrix}
	\begin{bmatrix}
		2 & 3 \\ 7 & 8 \\ 
	\end{bmatrix} =
	\begin{bmatrix}
		7 & 8 \\ 2 & 3
	\end{bmatrix}
\]

\[
	\begin{bmatrix}
		2 & 3 \\ 7 & 8 \\ 
	\end{bmatrix} 
	\begin{bmatrix}
		0 & 1 \\ 1 & 0\\
	\end{bmatrix}=
	\begin{bmatrix}
		3 & 2 \\ 8 & 7
	\end{bmatrix}
\]

Matrix multiplication:
\[
	\begin{bmatrix}
	a_{11} & a_{12} & a_{13} & ... & a_{1n} \\
	a_{21} & a_{22} & a_{23} & ... & a_{2n} \\
	... & &  & ... &  \\
	a_{m1} & a_{m2} & a_{m3}& ... & a_{mn} \\
	\end{bmatrix}
	\begin{bmatrix}
		x_1 \\ x_2 \\ ... \\ x_n
	\end{bmatrix} = 
	\begin{bmatrix}
		\sum_{i=1}^n a_{1i}x_i \\
		\sum_{i=1}^n a_{2i}x_i \\ 
		... \\
		\sum_{i=1}^n a_{ni}x_i\\
	\end{bmatrix}
\]

\[
	\begin{bmatrix}
		| & | &  & | \\
		a_1 & a_2 & ... & a_n \\
		| & | &  & | \\
	\end{bmatrix}
		\begin{bmatrix}
		x_1 \\ ... \\ x_n
	\end{bmatrix} = 
	a_1x_1+a_2x_2+...+a_nx_n
\]

\[
	\begin{bmatrix}
		| & | &  & | \\
		a_1 & a_2 & ... & a_n \\
		| & | &  & | \\
	\end{bmatrix}
	\begin{bmatrix}
		| &| \\
		b_1 & b_2 \\
		| & | \\
	\end{bmatrix} = 
	\begin{bmatrix}
		| & | \\
		Ab_1 & Ab_2 \\
		| & | \\
	\end{bmatrix} 
\]

\paragraph{Row reduction} In matrix form

\[
	A = \begin{bmatrix}
		2 & 1 & 1 \\
		4 & -6 & 0 \\
		-2 & 7 & 2 \\
	\end{bmatrix}
\]

\begin{enumerate}
	\item Subtract 2 times row 1 to row 2
	\[
		\begin{bmatrix}
			1 & 0 & 0 \\
			-2 & 1 & 0 \\
			0 & 0 & 1 \\
		\end{bmatrix}_{E_{21}}
		\begin{bmatrix}
			2 & 1 & 1 \\
			4 & -6 & 0 \\
			-2 & 7 & 2 \\
		\end{bmatrix}_A = 
		\begin{bmatrix}
			2 & 1 & 1 \\
			0 & -8 & -2 \\
			-2 & 7 & 2 \\
		\end{bmatrix}
	\]
	\item Subtract -1 times row 1 to row 3
	\[
		\begin{bmatrix}
			1 & 0 & 0 \\
			0 & 1 & 0 \\
			1 & 0 & 1 \\
		\end{bmatrix}_{E_{31}}
		E_{21}A = 
		\begin{bmatrix}
			2 & 1 & 1 \\
			0 & -8 & -2 \\
			0 & 8 & 3 \\
		\end{bmatrix}
	\]
	\item Subtract -1 times row 2 to row 3
	\[
		\begin{bmatrix}
			1 & 0 & 0 \\
			0 & 1 & 0 \\
			0 & 1 & 1 \\
		\end{bmatrix}_{E_{32}}
		E_{31}E_{21}A = 
		\begin{bmatrix}
			2 & 1 & 1 \\
			0 & -8 & -2 \\
			0 & 0 & 1 \\
		\end{bmatrix}
	\]
\end{enumerate}

Originally we wanted to solve $Ax=b$. Now we have:

\[
	E_{32}E_{31}E_{21}A = U
\]

where $U$ is an upper triangular matrix.

\[
	E_{32}E_{31}E_{21}Ax = Ux
\]

Let's let $E_{32}E_{31}E_{21} = L$. Then, we have

\[
	\begin{matrix}
		L^{-1}A=U \\
		A = LU \\
		Ux = C = E_{32}E_{31}E_{21}b
	\end{matrix}
\]

Now we can solve by back substitution.

\[
	L^{-1}=E_{32}E_{31}E_{21} = \begin{bmatrix}
		1 & 0 & 0 \\
		-2 & 1 & 0 \\
		-1 & 1 & 1 
	\end{bmatrix}
\]


Matrix inverse properties:

\[
	\begin{matrix}
		(AB)^{-1} = B^{-1}A^{-1} \\
		(A_1A_2...A_n)^{-1} = A_n^{-1}...A_2^{-1}A_1^{-1}
	\end{matrix}
\]

So we have:

\[
	L = \begin{bmatrix}
		1 & 0 & 0 \\
		2 & 1 & 0 \\
		-1 & -1 & 1
	\end{bmatrix} = E_{21}^{-1}E_{31}^{-1}E_{32}^{-1}
\]

\paragraph{Row reduction matrices} A matrix that subtracts $l$ times row $j$ from row $i$ is such that it includes $-l$ in row $i$, column $j$.

\[
	\begin{matrix}
			A = \begin{bmatrix}
		1 & 0 & 0 \\
		2 & 1 & 0 \\
		-1 & -1 & 1
	\end{bmatrix}_L
	\begin{bmatrix}
		2 & 1 & 1 \\
		0 & -8 & -2 \\
		0 & 0 & 1 \\
	\end{bmatrix}_U
	\end{matrix}
\]

$L$ is lower triangular and $U$ is upper triangular.

\begin{enumerate}
	\item Compute LU factorization
	\item Solve for $c$ in $Lc = b$ (forward substitution)
	\item Solve for $x$ in $Ux = c$ (back substitution)
\end{enumerate}

We want to solve $Ax=b$. We factor to get $LUx =b$. First we find $c$ such that $Lc = b$

\subsection{General Example}
\[
	\begin{bmatrix}
		l_{11} & 0 & 0 \\
		l_{21} & l_{22} & 0 \\
		l_{31} & l_{32} & l_{33}
	\end{bmatrix}
	\begin{bmatrix}
		c_1 \\ c_2 \\ c_3
	\end{bmatrix} = 
	\begin{bmatrix}
		b_1 \\ b_2 \\ b_3
	\end{bmatrix} \Rightarrow
	\begin{matrix}
		c_1 = b_1 / l_{11} \\
		c_2 = b_2 - b_1 l_{21}/ l_{11} \\
		c_3 = b_3 - l_{31}b_1 - l_{32}(b_2 - b_1 l_{21})
	\end{matrix}
\]

\[
	\begin{bmatrix}
		u_{11} & u_{12} & u_{13} \\
		0 & u_{22} & u_{23} \\
		0 & 0 & u_{33}
	\end{bmatrix}
	\begin{bmatrix}
		x_1 \\ x_2 \\ x_3
	\end{bmatrix} = 
	\begin{bmatrix}
		c_1 \\ c_2 \\ c_3
	\end{bmatrix} \Rightarrow
	\begin{matrix}
		x_3 = c_3/u_{33} \\
		x_2 = \frac{1}{u_{22}}(c_2 - u_{23}c_3/u_{33})\\
		x_1 = .....
	\end{matrix}
\]

\section{September 13 Lecture}

Announcements

\begin{itemize}
	\item Matlab tutorials (sections)
	\item Final projects
	\begin{itemize}
		\item Adjustment based on class size
		\item Pairs
	\end{itemize}
	\item Assignment 1 due Fri @ 7pm in Pierce 303
	\item Collaboration policy
\end{itemize}

From last time:

\begin{itemize}
	\item Linear equations $\rightarrow$ Matrix notation
	\item Column $j$ of $AB=Ab_j$
	\[
		A
		\begin{bmatrix}
			| & | &  & | \\
			b_1 & b_2 & ... & b_n \\
			| & | &  & | \\
		\end{bmatrix} = 
		\begin{bmatrix}
			Ab_1 & Ab_2 & ... & Ab_n \\
		\end{bmatrix} 
	\]
	\item Introduced the $LU$ factorization of square matrix $A$ (see general example at end of last lecture)
	\[
		Ax=b \Rightarrow LUx = b
	\]
\end{itemize}

\begin{enumerate}
	\item Find $LU$
	\item Solve for $c$ in $Lc=b$
	\item Solve for $x$ in $Ux=c$
\end{enumerate}

\paragraph{Example} $LU$ factorization

\[
	A = 
	\begin{bmatrix}
		1 & 0 & 1 \\ 
		2 & 2 & 2 \\
		3 & 4 & 5
	\end{bmatrix}
\]

\begin{enumerate}
	\item Subtract 2 times row 1 to row 2
	\[
		\begin{bmatrix}
			1 & 0 & 0 \\ 
			-2 & 1 & 0 \\
			0 & 0 & 1
		\end{bmatrix}_{E_{21}} A =
		\begin{bmatrix}
			1 & 0 & 1 \\ 
			0 & 2 & 0 \\
			3 & 4 & 5
		\end{bmatrix}
	\]
	\[
		E_{21}^{-1} = \begin{bmatrix}
			1 & 0 & 0 \\ 
			2 & 1 & 0 \\
			0 & 0 & 1
		\end{bmatrix}
	\]
	\item Subtract 3 times row 1 to row 2
	\[
		\begin{bmatrix}
			1 & 0 & 0 \\ 
			0 & 1 & 0 \\
			-3 & 0 & 1
		\end{bmatrix}_{E_{31}} E_{21} A =
		\begin{bmatrix}
			1 & 0 & 1 \\ 
			0 & 2 & 0 \\
			0 & 4 & 2
		\end{bmatrix}
	\]
	\item Subtract 2 times row 2 to row 3
	\[
		\begin{bmatrix}
			1 & 0 & 0 \\ 
			0 & 1 & 0 \\
			0 & -2 & 1
		\end{bmatrix}_E{32} E_{31} E_{21} A =
		\begin{bmatrix}
			1 & 0 & 1 \\ 
			0 & 2 & 0 \\
			0 & 0 & 2
		\end{bmatrix}_U
	\]
\end{enumerate}

\[
	L^{-1} = E_{32} E_{31} E_{21} = \begin{bmatrix}
		1 & 0 & 0
		-2 & 1 & 0
		-3 & -2 & 1
	\end{bmatrix}
\]

\[
	\begin{matrix}
		L^{-1}A = U \\
		L = E_{21}^{-1} E_{31}^{-1} E_{32}^{-1} \\
		L = \begin{bmatrix}
			1 & 0 & 0 \\
			2 & 1 & 0 \\
			3 & 2 & 0 \\
		\end{bmatrix}
	\end{matrix}
\]

\paragraph{Generalizing $LU$ factorization} To $n \times n$ matrix:
\[
	\begin{bmatrix}
		a_{11} & a_{12} & a_{13} & ... &  a_{1n} \\
		a_{21} & a_{22} & a_{23} & ... &  a_{2n} \\
		... & ... & ... & ... & ...  \\
		a_{n1} & a_{n2} & a_{n3} & ... &  a_{nn} \\
	\end{bmatrix}
\]

\begin{enumerate}
	\item Introduce zeros below $a_{11}$ by subtracting multiples of row 1
	\item Use multipliers $l = \frac{a_{i1}}{a_{11}}$
	\item Repeat 1 and 2 for $a_{22}^*,a_{33}^*$, ...
\end{enumerate}

Step 1:
\[
	\begin{array}{c|cccc}
		a_{11} & a_{12} & a_{13} & ... &  a_{1n} \\\hline
		0 & a_{22}^* & a_{23}^* & ... &  a_{2n}^* \\
		... & ... & ... & ... & ...  \\
		0 & a_{n2}^* & a_{n3}^* & ... &  a_{nn}^* \\
	\end{array}
\]

Step 2:
\[
	\begin{array}{c|c|ccc}
		a_{11} & a_{12} & a_{13} & ... &  a_{1n} \\\hline
		0 & a_{22}^* & a_{23}^* & ... &  a_{2n}^* \\\hline
		... & 0 & a_{33}^* & ... & a_{3n}^* \\
		... & ... & ... & ... & ...  \\
		0 & 0 & a_{n3}^* & ... &  a_{nn}^* \\
	\end{array}
\]

How many operations does this algorithm use?

\[
	\sum_{k=1}^n k^2 - \sum_{k=1}^n k = \frac{n(n+1)(2n+1)}{6} - \frac{n(n+1)}{2}
\]

\section{September 18 Lecture}

To review: solving $Ax=b$:
\begin{enumerate}
	\item Find $LU=A$
	\item Solve for $c$ in $Lc=b$ (forward substitution)
	\item Solve for $x$ in $Ux=c$ (back-subst)
\end{enumerate}

Multipliers to find $U$ are entries of $L$.

What is the \# of operations needed to get $LU$ factorization?

\[
	\approx {n^3 - n \over 3}
\]

\paragraph{Forward substitution} Number of operations:

$(n-1) + (n-2) + ... (1) \approx O(n^2)$

Back substitution is similar process (also $O(n^2)$). Most time consuming place is step 1.

\paragraph{Algorithm Failure} This $Ax=b$:

\[
	\begin{bmatrix}
		0 & 1 \\ 1 & 0
	\end{bmatrix}
	\begin{bmatrix}
		x_1 \\ x_2
	\end{bmatrix} = 
	\begin{bmatrix}
		1 \\ 1
	\end{bmatrix}
\]

has solution $\begin{bmatrix}
	1 \\ 1
\end{bmatrix}$. However, our algorithm won't find the answer because it can't switch rows. If the algorithm fails we have two options:

\begin{enumerate}
	\item We need to rearrange rows
	\item No solution
	\item Infinitely many solutions
\end{enumerate}

Example of (2):

\[
	\begin{bmatrix}
		0 & 1 \\ 0 & 0
	\end{bmatrix}
	\begin{bmatrix}
		x_1 \\ x_2
	\end{bmatrix} = 
	\begin{bmatrix}
		1 \\ 1
	\end{bmatrix}
\]

Example of (3):

\[
	\begin{bmatrix}
		0 & 1 \\ 0 & 1
	\end{bmatrix}
	\begin{bmatrix}
		x_1 \\ x_2
	\end{bmatrix} = 
	\begin{bmatrix}
		1 \\ 1
	\end{bmatrix}
\]

\paragraph{Fact} $\det(A) = \det(LU) = \det(L)\det(U)$

\[
	\det(U) = \prod_{i=1}^n u_{ii}
\]

\paragraph{Example} Consider this:

\[
	\begin{bmatrix}
		0.0001 & 1 \\ 1 & 1
	\end{bmatrix}
	\begin{bmatrix}
		x_1 \\ x_2
	\end{bmatrix} = 
	\begin{bmatrix}
		1 \\ 2
	\end{bmatrix}
\]

\[
	\begin{bmatrix}
		0.0001 & 1 \\ 0 & -9999
	\end{bmatrix}
	\begin{bmatrix}
		x_1 \\ x_2
	\end{bmatrix} = 
	\begin{bmatrix}
		1 \\ -9998
	\end{bmatrix}
\]

\[
	\Rightarrow x_2 = {9998 \over 9999}
\]

\[
	0.0001 x_1 + {9998 \over 9999} = 1
\]

\[
	\Rightarrow x_1= {10000 \over 9999}
\]

If we do all of this with limited precision (say 3 digits), we do the following:

\[
	\begin{bmatrix}
		0.0001 & 1 \\ 0 & -10^4
	\end{bmatrix}
	\begin{bmatrix}
		x_1 \\ x_2
	\end{bmatrix} = 
	\begin{bmatrix}
		1 \\ -10^4
	\end{bmatrix}
\]

\[
	\Rightarrow x_2 = 1
\]

Then if we use the first equation, we get

\[
	\Rightarrow x_1 = 0
\]

This is called \textbf{catastrophic cancellation}.

\section{September 20 Lecture}
First part of AM120 is to solve $Ax=b$ for arbitrary $\norm{A} = n$.

\[
	u_{11} = a_{11}, u_{22} = a_{22} 
\]

Pseudocode did not have 0s in $L$ and $U$. Second part of code is given $L$ and $b$, should output $c$. Third part takes $U$ and $c$ and outputs $x$.

Assignment 2 Due on Monday morning (9am).

This Doolittle algorithm can fail:
\begin{enumerate}
	\item If there is a pivot = 0
	\begin{enumerate}
		\item System is singular $\Rightarrow \det(A) = 0$. This means there is no solution or infinitely many solutions.
		\item We can exchange rows and `cure' system.
		\[
			\det(A) = \det(L) \det(U) = 1 \prod_{k=1}^n u_{kk}
		\]
	\end{enumerate}
\end{enumerate}


\paragraph{Example} From last class:

\[
	\begin{bmatrix}
		0.0001 & 1 \\ 1 & 1
	\end{bmatrix}
	\begin{bmatrix}
		x_1 \\ x_2
	\end{bmatrix} = 
	\begin{bmatrix}
		1 \\ 2
	\end{bmatrix}
\]

This had true solution:

\[
		x_1 = {10000 \over 9999}, x_2 = {9998 \over 9999}
\]

But with limited precision (three digit arithmetic), we got:

\[
		x_1 = 0, x_2 = 1
\]

What if we switch the rows?

\[
	\begin{bmatrix}
		1 & 1 \\ 0.0001 & 1
	\end{bmatrix}
	\begin{bmatrix}
		x_1 \\ x_2
	\end{bmatrix} = 
	\begin{bmatrix}
		2 \\ 1
	\end{bmatrix}
\]

\[
	\begin{bmatrix}
		1 & 0 \\ 10^{-4} & 1
	\end{bmatrix}_L
	\begin{bmatrix}
		1 & 1 \\ 0 & 1
	\end{bmatrix}
	\begin{bmatrix}
		x_1 \\ x_2
	\end{bmatrix} =
	\begin{bmatrix}
		2 \\ 1 - 2 \cdot 10^{-4}t
	\end{bmatrix}
\]

\subsection{Finite precision}

The computer represents a floating point number with a sign, exponent, and digits for the value itself. When we are talking about $n$-digit arithmetic, we are referring to the number of digits storing the value.

\[
	\begin{matrix}
		U = \text{max exponent} \\
		L = \text{lowest exponent} \\
		P = \text{mantissa number of digits} \\
		\beta = \text{base} \\
	\end{matrix}
\]

For example, for $L=-1, U=1, p=2$ and $\beta = 10$:

\[
	\text{(sign)} d_0 . d_1 d_2 ... d_p \times 10^{\text{exponent}}
\]

\[
	\begin{matrix}
		\text{largest} & 9.9 \times 10^1 = 99\\
		\text{smallest (non-zero)} & 1.0 \times 10^{-1} = 0.1
	\end{matrix}
\]

Examples of real values in floating point systems:

\[
	\begin{matrix}
		& \beta & P & L & U \\
		\text{IEEE} & 2 & 24 & -126 & 123 & \text{single} \\
					& 2 & 53 & -1022 & 1023 & \text{double}\\ 
		\text{HP}   & 10 & 12 & -499 & 499
	\end{matrix}
\]

What is the total number of floating point numbers?

\[
	2(\beta - 1) \beta^{p-1} (u-l+1) + 1
\]

Largest representable number:

\[
	(\beta - 1).(\beta - 1)...(\beta - 1) \cdot \beta^U
\]

Smallest number (absolute value):

\[
	\beta^L (\text{underflow})
\]

\paragraph{Machine precision} Note that the difference between the real number and the floating point number chosen depends on exponent.

\[
	\forall x \in R, \exists \text{fl}(x) = \hat{x} \text{ such that } \abs{x-\hat{x}} \leq \sum \abs{x}
\]

Note that this is not really true for all $x \in R$ -- only within a certain range. $\epsilon_{\text{mach}}$ is the largest number s.t. fl($1 + \epsilon_{\text{mach}}) > 1$.

Floating point numbers are not associative:

\[
	A+(B+C)) \not= (A+B)+C
\]

\section{September 27 Lecture}

\paragraph{Last Class} Theory: For a non-singular and square matrix $A$, $\exists P$ (permutation matrix) that reorders rows of $A$ to avoid zeroes in the pivot positions

$Ax=b$ has a unique solution, and with the rows ordered ``in advance:''

\[
	P A = L U \text{ where } L \text{ and } U \text{ are unique.}
\]

Note: If $A$ is singular, no $P$can produce a full set of pivots and elimination fails.

Gaussian elimination with partial pivoting: if a pivot is zero, then $A$ is singular

\[
	A x = 
	\begin{bmatrix}
		0 & 4 & 1 \\
		1 & 1 & 3 \\
		2 & -2 & 1
	\end{bmatrix}
	\begin{bmatrix}
		x_1 \\ x_2 \\ x_3
	\end{bmatrix} = 
	\begin{bmatrix}
		9 \\ 6 \\ -1
	\end{bmatrix} = 
	b
\]

\[
	PA =
	\begin{bmatrix}
		2 & -2 & 1 \\
		0 & 4 & 1 \\
		1 & 1 & 3
	\end{bmatrix},
	P = 
	\begin{bmatrix}
		0 & 0 & 1 \\
		1 & 0 & 0 \\
		0 & 1 & 0
	\end{bmatrix}
\]

\[
	\tilde{A} = PA = LU = 
	\begin{bmatrix}
		1 & 0 & 0
		0 & 1 & 0
		1/2 & 1/2 & 1
	\end{bmatrix}_{\tilde{L}}
	\begin{bmatrix}
		2 & -2 & 1
		0 & 4 & 1
		0 & 0 & 6
	\end{bmatrix}_{\tilde{U}}
\]

% for k = 1:n-1
% 	find p such that |a(p,k)| > |a(i,k)| for k <= i <= n
%	if p != k then
%		interchange rows k and p (and record permutation)
%	if a_kk = 0 then STOP

\subsection{Ill-conditioned Matrices}

The presence of round-off error makes it difficult to identify singular matrices.

\[
	A =
	\begin{bmatrix}
		1000 & 999 \\ 999 & 998		
	\end{bmatrix}	
	\rightarrow
	\begin{bmatrix}
		1 & 0 \\ .999 & 1
	\end{bmatrix}_L
	\begin{bmatrix}
		1000 & 999 \\
		0 & -.001
	\end{bmatrix}_U
\]


\[
	Ax = b = \begin{bmatrix} 1999 \\ 1997 \end{bmatrix}
	\rightarrow
	x = \begin{bmatrix} 1 \\ 1 \end{bmatrix}
\]

With limited precision (5-digit arithmetic), $A$ appears singular, because 0.999(999)=998.00.

\[
	Ax = \hat{b} = \begin{bmatrix} 1998.99 \\ 1997.01 \end{bmatrix} =
	b + \delta b = b + 10^{-2} \begin{bmatrix} -1 \\ 1 \end{bmatrix}
	\Rightarrow
	x = \begin{bmatrix} 20.97 \\ -18.99 \end{bmatrix}
\]

Small change in $b$ and same $A$, $x$ changes a lot. We call $A$ `ill-conditioned,' meaning that its `condition number,' $k(A)$ is big. This is the definition of condition number:

\[
	{\norm{\delta x} \over \norm{x}} \leq k(A) {\norm{\delta b} \over \norm{b}}
\]

Hilbert matrices are of this kind: changing $b$ a little bit, $x$ changes a lot (they are ill conditioned). Condition number of a singular matrix $A$ is $\infty$.

If ${\norm{\delta x} \over \norm{x}} > 1$ we don't expect to find a solution close to the one we were looking for.

In numberical calculations, singular matrices are indistinguishable from ill-conditioned matrix.


\[
	\begin{matrix}
		-{d^2 u \ over dx^2} = f(x), 0 \leq x \leq 1 \\
		u(0) = c_1
		u(1) = c_2
	\end{matrix}
\]

\[
	u(x+h) = u(x) + h u'(x) + h^2 {u''(x) \over 2} + ... + h^k {d^k u \over d x^k}
\]

Discretize interval into points $x_i$, solve for value of $u$ at each point. At each point we can solve the problem as a linear algebra problem. We ignore higher terms, and say:

\[
	u'(x_i) \approx {u(x_i+h) - u(x_i) \over h}
\]

\[
	-u''(x_i) \approx -{u(x_{i+1} - 2 u(x_i) + u(x_{i-1})) \over h^2 } = f(x_i)
\]

This results in a large matrix:

\[
	\begin{bmatrix}
		2 & -1 \\
		-1 & 2 & -1 \\
		0 & -1 & 2 & -1 \\
		 & & & & \ddots \\ \\ \\
	\end{bmatrix}
	\begin{bmatrix}
		u_1 \\ u_2 \\ \vdots \\ u_m
	\end{bmatrix}
	=
	\begin{bmatrix}
		f(x_1) \\ \\ \vdots \\ f(x_m)
	\end{bmatrix}
\]

\section{October 2 Lecture}

\paragraph{Last class} Condition numbers. Blah blah blah blah blah.

We have implemented solving $Ax = b$ the same way that MATLAB's ``$\backslash$'' function works. Now we move on to other things.

\subsection{Over/underconstrained Systems}

\[
	-{d^2 u \over dx^2} = f(x), u(0) = \alpha, u(1) = \beta
\]

Approximation of second derivative at discrete point $x_i$:

\[
	-{d^2 u (x_i) \over dx^2} \approx {u(x_{i+1}) - 2u(x_i)+u(x_{i-1})) \over h^2}
\]

\[
	h^2 f(x_i) \approx u(x_{i+1}) - 2u(x_i)+u(x_{i-1}))
\]

At the boundary:

\[
	h^2 f(x_1) \approx u(x_{2}) - 2u(x_1)+\alpha
\]

We got this from this, ignoring smaller terms:

\[
	u(x+h) = u(x) + {du \over dx}(x) h + {d^2u \over dx^2} {h^2 \over 2} + ... 
\]

This yields:

\[
	\begin{bmatrix}
		2 & -1 \\
		-1 & 2 & -1 \\
		0 & -1 & 2 & -1 \\
		 & & & & \ddots \\ \\ \\
	\end{bmatrix}
	\begin{bmatrix}
		u(x_1) \\ u(x_2) \\ \vdots \\ u(x_m)
	\end{bmatrix}
	=
	\begin{bmatrix}
		-\alpha + f(x_1)h^2 \\ f(x_2)h^2\\ \vdots \\ -\beta + f(x_m)h^2
	\end{bmatrix}
\]

Need to solve $Ax = b$. Now we are studying methods that have to do with matrices that are not square! First, we'll say $m < n$:

\[
	\begin{bmatrix}
		& & & & & & \\
		& & & A & & & \\
		& & & & & &
	\end{bmatrix}_{m \times n}
	\begin{bmatrix}
		\\ \\ \\ x \\ \\ \\ \\
	\end{bmatrix}_{n \times 1} =
	\begin{bmatrix}
		\\ b \\ \\
	\end{bmatrix}_{m \times 1}
\]

The left side of $A$ has an $m \times m$ square section. This is underdetermined, so there are many solutions. What is $m > n$:

\[
	\begin{bmatrix}
		\\
		 \\
		& A &\\
		\\
		\\
	\end{bmatrix}_{m \times n}
	\begin{bmatrix}
		\\ x \\ \\
	\end{bmatrix}_{n \times 1} =
	\begin{bmatrix}
		\\ \\ \\ b \\ \\ \\ \\
	\end{bmatrix}_{m \times 1}
\]

This is an overconstrained system, which may not have a solution. A real example of this is fitting a line to points in a least-squares sense. If each point is at $(t_i, y_i)$, and we want to find a line $y = mt + b$, then we solve:

\[
	\begin{bmatrix}
		t_1 & 1\\
		t_2 & 1\\
		\vdots \\
		t_m & 1
	\end{bmatrix}_A
	\begin{bmatrix}
		m \\ b
	\end{bmatrix}_x =
	\begin{bmatrix}
		y_1 \\ y_2 \\ \vdots \\ y_m
	\end{bmatrix}_b
\]

\subsection{Vector Spaces}
\textbf{Vector spaces} have two operations:

[Example: $\bbR^n$]

\begin{enumerate}
	\item if $x,y \in \bbR^n$, $x+ y = z \in \bbR^n$
	\item if $x \in \bbR^n, \alpha \in \bbR$, $\alpha x \in \bbR^n$
\end{enumerate}

These properties must hold:

\textbf{Addition}: for $x, y, z \in \bbR^n$
\begin{enumerate}
	\item Commutativity: $x + y = y + x$
	\item Associativity: $x + (y + z) = (x + y) + z$
	\item $\exists!$\footnote{`!' indicates there exists some unique zero vector} zero vector s.t. $x + 0 = x \forall x \in \bbR^n$
	\item $\exists! -x \in \bbR^n$ s.t. $x + (-x) = 0 \forall x \in \bbR^n$

	\textbf{Scalar multiplication}

	\item $1 x = x$ : 1 is scalar
	\item $(c_1 c_2) x = c_1(c_2x)$
	\item $c(x+y) = cx + cy$
	\item $(c_1 + c_2)x = c_1 x + c_2 x$
\end{enumerate}

A \textbf{subspace} is a non-empty subset of a vector space that satisfies all these properties and all linear combinations stay in the subspace.

\paragraph{Example}

\[
	\begin{bmatrix}
		1 & 0 \\ 5 & 4 \\ 4 & 4 \\
	\end{bmatrix}
	\begin{bmatrix}
		u \\ v
	\end{bmatrix} 
	=
	\begin{bmatrix}
		1 \\ 5 \\ 4
	\end{bmatrix} u
	\begin{bmatrix}
		0 \\ 4 \\ 4
	\end{bmatrix} v
\]

\section{October 4 Lecture}

Use `$\backslash$' operator in MATLAB from now on unless we specify otherwise. Assignment 4 is now due Tuesday in class.

\paragraph{Last class} We discussed vector spaces, with the intention of being able to solve any linear algebra problem, whether it be overdetermined or underdetermined. Vector spaces have two operations, addition and scalar multiplication, with 8 axioms. Note: no notion of proximity or distance (no topology).

\paragraph{Subspace} A non-empty subset of a vector space. Closed under addition and scalar multiplication. ($x+y \in$ subspace, $ax \in$ subspace).

\[
	\begin{matrix}
		\bbR^2 & \text{smallest sub-space} & \text{\{zero\} element} \\
		 & \begin{bmatrix}
		 	0 \\ 0
		 \end{bmatrix} \\
		 & \text{largest sub-space} & \bbR^2 \\\hline
		 \bbR^3 & \begin{bmatrix}
		 	0 \\ 0 \\0 
		 \end{bmatrix} \\
		 & \text{planes and lines that go through } \begin{bmatrix}
		 	0 \\ 0 \\ 0
		 \end{bmatrix} \text{ are subspaces.}
	\end{matrix}
\]

\[
	A = \begin{bmatrix}
		1 & 0 \\ 5 & 4 \\ 2 & 4
	\end{bmatrix},
	x = \begin{bmatrix}
		x_1 \\ x_2
	\end{bmatrix}, 
	Ax = \begin{bmatrix}
		1 \\ 5 \\ 2 
	\end{bmatrix} x_1 + 
	\begin{bmatrix}
		0 \\ 4 \\ 4
	\end{bmatrix} x_2
\]

Column spaces of $A$ (denoted $C(A)$) is the spaces that contains all linear combinations of the columns of $A$.

If we have a matrix $\begin{bmatrix}A\end{bmatrix}_{M \times N}$ (with $m$ rows, $n$ columns), then $C(A) \in \bbR^m$.

$b$ and $\tilde{b} \in C(A), \exists x$ and $\tilde{x}$

\[
	\begin{matrix}
		Ax = b & A(x+\tilde{x}) = b + \tilde{b}\\
		A \tilde{x}  = \tilde{b} \\
		c b & A(cx) = cAx = cb
	\end{matrix}
\]	

Null space:

\[
	A = \begin{bmatrix}
		1 & 0 \\ 0 & 1 \\ 0 & 0
	\end{bmatrix}
\]	

Null space of $A$ consists of all vectors $x$ such that $Ax = 0$, denoted $N(A) \in \bbR^n$.

\[
	Ax = \begin{bmatrix}
		1 \\ 5 \\ 2
	\end{bmatrix} x_1 + 
	\begin{bmatrix}
		0 \\ 4 \\ 4
	\end{bmatrix} x_2 = 
	\begin{bmatrix}
		0 \\ 0 \\ 0
	\end{bmatrix}
\]

\[
	\begin{bmatrix}
		x_1 \\ x_2
	\end{bmatrix} \in N(A),
	\begin{bmatrix}
		0 \\ 0
	\end{bmatrix} \in N(A)
\]

\paragraph{Theorem} If zero is the only element of $N(A) \Rightarrow$ columns of $A$ are linearly independent.

If $N(A) = \{0\}$ and $A$ is a square matrix $\Rightarrow \exists! x$ such that $Ax = b$ for any $b$.

Basis for a \textbf{vector space} $V \{v_k\}$.

\begin{enumerate}
	\item $v_k$'s are linearly independent
	\item they span $V$ (any $v \in V$ is a linear combination of the basis vectors $\{v_k\}$)
\end{enumerate}

\[
	\Rightarrow \exists! \text{ way to represent any element of } V
\]

\[
	text{dim}(V) = \text{ \# of basis vectors}
\]

The \textbf{complete solution} of a linear system of equations

\[
	 Ax=b \text{ is given by } x = x_p + x_n \text{ (if it exists)}
\]

where

\[
	Ax_p = b and Ax_n = 0
\]

\[
	A(x_p + x_n) = b + 0 = b
\]

\[
	\begin{matrix}
		A = \begin{bmatrix}
			1 & 2 \\ 2 & 4
		\end{bmatrix} &
		C(A) = k \begin{bmatrix}
			1 \\ 2
		\end{bmatrix} \text{ line}\\
		& N(A) = d \begin{bmatrix}
			2 \\ -1
		\end{bmatrix} \text{ line}
	\end{matrix}
\]

\[
	\begin{bmatrix}
		1 & 2 \\ 2 & 4
	\end{bmatrix}
	\begin{bmatrix}
		x_1 & x_2
	\end{bmatrix} = Ax  = b = \begin{bmatrix}
		3 \\ 6
	\end{bmatrix}
\]

\[
	x = \begin{bmatrix}
		3 \\ 0
	\end{bmatrix}_{x_{p}} + d \begin{bmatrix}
		2 \\ -1
	\end{bmatrix}_{x_{n}}
\]

\paragraph{Theorem}: For any $m \times n$ matrix $A \exists P$ (permutation) and $L$ lower triangular matrix and an $m \times n$ Echelon matrix $U$ such that $PA = LU$

\[
	A = \begin{bmatrix}
		1 & 3 & 3 & 2 \\
		2 & 6 & 9 & 7 \\
		-1 & -3 & 3 & 4
	\end{bmatrix}
\]

Let's find $LU$:

\[
	L = \begin{bmatrix}
		1 & 0 & 0\\
		2 & 1 & 0\\
		-1 & 2 & 1 \\
	\end{bmatrix},
	U = \begin{bmatrix}
		1 & 3 & 3 & 2 \\
		0 & 0 & 3 & 3 \\
		0 & 0 & 0 & 0
	\end{bmatrix}
\]

Note that $L$ is $m \times m$ square, and $U$ is also $m \times n$. Also, we see that $U$ has 2 LI columns.

We already knew that the column space of $A$ lives in $\bbR^3$, so one column had to be dependent. Now we know that only two vectors in the 4 columns are LI, so the column space is a plane. Null space is also a plane, but it lives in $\bbR^4$.

Another example:

\[
	\begin{matrix}
		(t_1, y_1)' = (0,0) \\
		(t_2, y_2) = (2,1)\\
		\begin{bmatrix}
			1 & 0 \\ 1 & 2
		\end{bmatrix}_A
		\begin{bmatrix}
			x_1 \\ x_2
		\end{bmatrix} = 
		\begin{bmatrix}
			0 \\ 1
		\end{bmatrix}
	\end{matrix}
\]

\[
	\begin{matrix}
		y = P(t) = x_1 + x_2 t \\
		y_1 = P(t_1) = x_1 + x_2 t_1 \\
		y_2 = P(t_2) = x_1 + x_2 t_2
	\end{matrix}
\]

We get $P = {1 \over 2 } t$

\end{document}
